{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rat Sightings Data Cleaning\n",
    "\n",
    "This notebook cleans the data in scr/data/rat_sightings_data/Rat_Sightings_NYC.csv and saves the results to sc/data/Rat_Sightings_Cleaned.csv. The main steps of our cleaning process is summaried here.\n",
    "\n",
    "1. We first cleaned up the column names by making words lowercase and replacing spaces by underscores.\n",
    "\n",
    "2. We updated all entries in the data which are dates to pandas datetime format.\n",
    "\n",
    "3. We dropped columns with only 1 unique value since they provide no information for later analysis.\n",
    "\n",
    "4. We cleaned up the values of the location_type columns by shortening the strings. We used a dictionary and a mapping to keep track of the changes.\n",
    "\n",
    "5. We consolidated redundant columns such as park_borough being the same as borough.\n",
    "\n",
    "6. We checked that the location column was redundant due to the prescence of the latitude and longitude column. Then, we dropped the location column.\n",
    "\n",
    "7. The rat sightings data includes information on when the case was opened and closed. We added a column which tracks the number of days it took to close each case. Doing this, we found two entries with a close date occuring before the open date.\n",
    "\n",
    "8. The incident_zip column contains the value 12345 which does not correspond to a zip code in NYC. We update the incident_zip by using the latitude and longitude columns. \n",
    "\n",
    "9. We save the cleaned data to a new csv file for later use. At the end, we quantified the missingness of the data using missingno's matrix and heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3865674",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_sighting = pd.read_csv(\"../data/rat_sightings_data/Rat_Sightings_NYC.csv\")\n",
    "rat_sighting.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make letters lowercase, replace spaces with underscores, get rid of text after '(' etc\n",
    "\n",
    "rat_sighting.columns = [t.partition('(')[0].strip().lower().replace(' ', '_') for t in rat_sighting.columns] #apply to column headers\n",
    "rat_sighting['location_type'] = rat_sighting['location_type'].str.strip().str.replace(' ', '_').str.lower()  #apply to location_type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify columns with only 1 unique value (including NaNs)\n",
    "cols_to_drop = [c for c in rat_sighting.columns if (rat_sighting[c].nunique(dropna=False) == 1)]\n",
    "\n",
    "# Drop them all in one go\n",
    "rat_sighting = rat_sighting.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the datetime the correct format\n",
    "rat_sighting['created_date'] = pd.to_datetime(rat_sighting['created_date']) \n",
    "rat_sighting['closed_date'] = pd.to_datetime(rat_sighting['closed_date'])\n",
    "rat_sighting['resolution_action_updated_date'] = pd.to_datetime(rat_sighting['resolution_action_updated_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b914e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_sighting['location_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4178264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the \"wrong\" names and the \"right\" name\n",
    "mapping = {\n",
    "    '3+_family_apartment_building': '3+_family_apt._building',\n",
    "    '3+family_apt.': '3+_family_apt._building',\n",
    "    '3+_family_apt.': '3+_family_apt._building',\n",
    "    '3+_family_apt': '3+_family_apt._building',\n",
    "    'residential_building': '3+_family_apt._building',\n",
    "    'residence': '3+_family_apt._building',\n",
    "    'apartment': '3+_family_apt._building',\n",
    "    '1-2_familydwelling': '1-2_family_dwelling',\n",
    "    'school': 'school/pre-school/nursery',\n",
    "    'school/pre-school': 'school/pre-school/nursery',\n",
    "    'day_care_or_nursery': 'school/pre-school/nursery',\n",
    "    'day_care/nursery': 'school/pre-school/nursery',\n",
    "    'street':'street_area',\n",
    "    'restaurant': 'restaurant/bar/deli/bakery',\n",
    "    'catch_basin_or_sewer': 'catch_basin/sewer',\n",
    "    'parking_lot_or_garage': 'parking_lot/garage',\n",
    "    'government_building': 'office/government_building',\n",
    "    'office/government_ building': 'office/government_building',\n",
    "    'other_(explain_below)': 'other'\n",
    "}\n",
    "\n",
    "# Apply the fix\n",
    "rat_sighting['location_type'] = rat_sighting['location_type'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3499ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_sighting['location_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if park_borough and borough columns are redundant\n",
    "print(rat_sighting['park_borough'].equals(rat_sighting['borough']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380531b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_sighting = rat_sighting.drop(columns='park_borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice that information from lat, lon are repeated in point\n",
    "\n",
    "# 1. Update the mask to ensure both lat and lon are present\n",
    "not_null_mask = (\n",
    "    rat_sighting['location'].notnull() & \n",
    "    rat_sighting['longitude'].notnull() & \n",
    "    rat_sighting['latitude'].notnull()\n",
    ")\n",
    "\n",
    "# 2. Extract BOTH lon and lat from the POINT string\n",
    "# POINT (-73.9685 40.7540) -> index 0 is lon, index 1 is lat\n",
    "coords_from_point = rat_sighting['location'].str.extract(r'POINT \\(([^ ]+) ([^)]+)\\)').astype(float)\n",
    "\n",
    "# 3. Check if extracted lon matches 'longitude' AND extracted lat matches 'latitude'\n",
    "lon_matches = np.isclose(coords_from_point.loc[not_null_mask, 0], rat_sighting.loc[not_null_mask, 'longitude'], atol=1e-4)\n",
    "lat_matches = np.isclose(coords_from_point.loc[not_null_mask, 1], rat_sighting.loc[not_null_mask, 'latitude'], atol=1e-4)\n",
    "\n",
    "# 4. Combine them: True only if BOTH match\n",
    "final_matches = lon_matches & lat_matches\n",
    "\n",
    "print(pd.Series(final_matches).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd80677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the `location' column since it is redundant with latitude and longitude.\n",
    "\n",
    "rat_sighting = rat_sighting.drop(columns=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492bdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Strip out the word 'Unspecified' and extra spaces from the community board column\n",
    "cleaned_board = rat_sighting['community_board'].str.replace('Unspecified', '', case=False).str.strip()\n",
    "\n",
    "# 2. Extract the borough name from what remains (e.g., '03 BRONX' -> 'BRONX')\n",
    "extracted_borough_cleaned = cleaned_board.str.extract(r'\\d*\\s*(.*)')\n",
    "\n",
    "# 3. Re-run the comparison\n",
    "matches_new = (extracted_borough_cleaned[0] == rat_sighting['borough'])\n",
    "\n",
    "# 4. Check the results\n",
    "print(pd.Series(matches_new).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'matches' to 'matches_new' to see the actual errors\n",
    "mismatches = rat_sighting[matches_new == False]\n",
    "\n",
    "# Show the columns side-by-side\n",
    "mismatches[['community_board', 'borough']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c10ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where both dates exist\n",
    "both_dates_exist = rat_sighting['created_date'].notnull() & rat_sighting['closed_date'].notnull()\n",
    "\n",
    "# Compare only the valid rows\n",
    "real_date_mismatches = rat_sighting[\n",
    "    (rat_sighting['created_date'] != rat_sighting['closed_date']) & \n",
    "    both_dates_exist\n",
    "]\n",
    "\n",
    "print(f\"Actual mismatches (excluding NaT): {len(real_date_mismatches)}\")\n",
    "real_date_mismatches[['created_date', 'closed_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_count = rat_sighting['closed_date'].count()\n",
    "closed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bccc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rat_sighting['status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter for rows where status is exactly 'Unspecified'\n",
    "unspecified_status_rows = rat_sighting[rat_sighting['status'] == 'Unspecified']\n",
    "\n",
    "# Print the resulting rows\n",
    "unspecified_status_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87af7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for status 'In Progress' that also have a closed_date\n",
    "in_progress_with_dates = rat_sighting[\n",
    "    (rat_sighting['status'] == 'In Progress') & \n",
    "    (rat_sighting['closed_date'].notnull())\n",
    "]\n",
    "\n",
    "# Display the findings\n",
    "in_progress_with_dates[['unique_key', 'status', 'created_date', 'closed_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where status is 'In Progress' but a closed_date exists\n",
    "status_mismatch = rat_sighting[\n",
    "    (rat_sighting['status'] == 'In Progress') & \n",
    "    (rat_sighting['closed_date'].notnull())\n",
    "]\n",
    "\n",
    "print(f\"Rows that are 'In Progress' but have a date: {len(status_mismatch)}\")\n",
    "status_mismatch[['unique_key', 'status', 'created_date', 'closed_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the column first\n",
    "rat_sighting['days_to_close'] = (rat_sighting['closed_date'] - rat_sighting['created_date']).dt.days\n",
    "\n",
    "# 2. Now you can filter for negative values\n",
    "time_travelers = rat_sighting[rat_sighting['days_to_close'] < 0]\n",
    "\n",
    "# 3. Display the results\n",
    "time_travelers[['unique_key', 'created_date', 'closed_date', 'days_to_close']]\n",
    "\n",
    "# Filter for rows where the math resulted in a negative number\n",
    "time_travelers = rat_sighting[rat_sighting['days_to_close'] < 0]\n",
    "\n",
    "# Display the key columns to see the date conflict\n",
    "time_travelers[['unique_key', 'created_date', 'closed_date', 'days_to_close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter for only the 'Closed' status rows\n",
    "closed_only = rat_sighting[rat_sighting['status'] == 'Closed'].copy()\n",
    "\n",
    "# 2. Recalculate the days to close for this subset\n",
    "closed_only['days_to_close'] = (\n",
    "    (closed_only['closed_date'] - closed_only['created_date']).dt.total_seconds() / 86400\n",
    ")\n",
    "\n",
    "# 3. See the summary\n",
    "print(closed_only['days_to_close'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4130ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The zip code 12345 are invalid. \n",
    "rat_sighting[rat_sighting['incident_zip']== 12345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fix the zip_code issue for these values\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# load the zip_code data\n",
    "zip_db = pd.read_csv(\"map_data_for_cleaning/uszips.csv\")\n",
    "zip_db = zip_db[['zip', 'lat', 'lng']].dropna()\n",
    "\n",
    "# Remove invalid (NaN or inf) coordinates\n",
    "zip_db = zip_db[np.isfinite(zip_db['lat']) & np.isfinite(zip_db['lng'])]\n",
    "\n",
    "# Build KDTree\n",
    "tree = cKDTree(zip_db[['lat', 'lng']].values)\n",
    "\n",
    "def nearest_zip(lat, lon):\n",
    "    \"\"\"Return ZIP code nearest to a given latitude/longitude.\"\"\"\n",
    "    if not np.isfinite(lat) or not np.isfinite(lon):\n",
    "        return pd.NA  # skip invalid coordinates\n",
    "    distance, idx = tree.query([lat, lon])\n",
    "    return int(zip_db.iloc[idx]['zip'])\n",
    "\n",
    "# fix problematic rows\n",
    "zip_codes_to_fix = {12345}\n",
    "mask = rat_sighting['incident_zip'].isin(zip_codes_to_fix)\n",
    "\n",
    "# Only apply to rows with valid lat/lon\n",
    "valid_mask = mask & rat_sighting['latitude'].notna() & rat_sighting['longitude'].notna()\n",
    "\n",
    "rat_sighting.loc[valid_mask, 'incident_zip'] = rat_sighting.loc[valid_mask].apply(\n",
    "    lambda r: nearest_zip(r['latitude'], r['longitude']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use ZIP codes quite frequently, so it is convenient to change incident_zip to zip.\n",
    "\n",
    "rat_sighting.rename(columns={'incident_zip':'zip'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned up rat_sighting data to a new CSV file\n",
    "\n",
    "rat_sighting.to_csv(\"../data/cleaned_rat_sightings_data/cleaned_rat_sightings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642900b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a sample of the cleaned up data\n",
    "\n",
    "rat_sighting.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c481e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check missingness of the data.\n",
    "\n",
    "msno.matrix(rat_sighting)\n",
    "msno.heatmap(rat_sighting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
