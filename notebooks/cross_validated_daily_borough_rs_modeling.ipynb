{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216b5b0d",
   "metadata": {},
   "source": [
    "# SARIMA with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e695a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Patch\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ab1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../scr/data/cleaned_rat_sightings_data/daily_borough_rs.csv\")\n",
    "\n",
    "RMSE=[]\n",
    "\n",
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd03e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = '2025-06-01'\n",
    "before_cut_off = '2025-05-31'\n",
    "last_day = '2025-09-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c9aee",
   "metadata": {},
   "source": [
    "## Simplifications\n",
    "\n",
    "For now, we focus solely on Manhattan. First, let us recall the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193efc41",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebe7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdate_borough_test = df[df['created_date']>=cut_off]\n",
    "cdate_borough_test = cdate_borough_test[cdate_borough_test['created_date']<=last_day]\n",
    "\n",
    "cdate_borough = df[df['created_date']<cut_off]\n",
    "cdate_borough = cdate_borough[cdate_borough['created_date']>='2020-01-01']\n",
    "\n",
    "\n",
    "boroughs = [b for b in df['borough'].unique() if pd.notnull(b) and b != 'Unspecified']\n",
    "\n",
    "\n",
    "def seasonal_average_forecast(data, target_dates, years_back=5, day_window=5):\n",
    "    df = data.copy()\n",
    "    df[\"created_date\"] = pd.to_datetime(df[\"created_date\"])\n",
    "    df[\"doy\"] = df[\"created_date\"].dt.dayofyear\n",
    "    df[\"year\"] = df[\"created_date\"].dt.year\n",
    "\n",
    "    forecasts = []\n",
    "    for target_date in target_dates:\n",
    "        target_doy = target_date.dayofyear\n",
    "        target_year = target_date.year\n",
    "        mask = (\n",
    "            (df[\"year\"] >= target_year - years_back) &\n",
    "            (df[\"year\"] < target_year) &\n",
    "            (np.abs(df[\"doy\"] - target_doy) <= day_window)\n",
    "        )\n",
    "\n",
    "        forecasts.append(df.loc[mask, \"count\"].mean())\n",
    "\n",
    "    return pd.Series(forecasts, index=target_dates)\n",
    "\n",
    "\n",
    "# ensure global dataframe is datetime\n",
    "cdate_borough[\"created_date\"] = pd.to_datetime(cdate_borough[\"created_date\"])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(50,80))\n",
    "gs = gridspec.GridSpec(5,1, figure=fig, wspace=0.3, hspace=0.3)\n",
    "\n",
    "colors = [\"r\", \"b\", \"g\", \"purple\", \"b\"]\n",
    "\n",
    "for i, borough in enumerate(boroughs):\n",
    "    ax = fig.add_subplot(gs[i])\n",
    "\n",
    "    borough_data = cdate_borough[cdate_borough[\"borough\"] == borough].assign(created_date=lambda df: pd.to_datetime(df[\"created_date\"])).sort_values(\"created_date\").set_index(\"created_date\")\n",
    "\n",
    "    # create a complete daily date range\n",
    "    full_range = pd.date_range(start=\"2020-01-01\", end=before_cut_off, freq=\"D\")\n",
    "\n",
    "    # reindex and fill missing days with 0\n",
    "    borough_data = borough_data.reindex(full_range).assign(count=lambda df: df[\"count\"].fillna(0),borough=borough).rename_axis(\"created_date\").reset_index()\n",
    "\n",
    "    borough_data_test = cdate_borough_test[cdate_borough_test[\"borough\"] == borough].sort_values(\"created_date\").copy()\n",
    "        \n",
    "    last_date = cdate_borough[\"created_date\"].max()\n",
    "    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=len(borough_data_test), freq=\"D\")\n",
    "    \n",
    "    # compute seasonal-average forecast\n",
    "    forecast = seasonal_average_forecast(borough_data,future_dates,years_back=5)\n",
    "\n",
    "    # plot observed data\n",
    "    ax.plot(borough_data[\"created_date\"].dt.to_pydatetime(), borough_data[\"count\"], \"o\", color=colors[i], markersize=10, label=\"Observed\")\n",
    "\n",
    "    # plot forecast\n",
    "    ax.plot(forecast.index, forecast.values, color=\"black\", linewidth=5, linestyle = \"-\", label=\"Seasonal Avg Forecast\")\n",
    "\n",
    "    borough_data_test[\"created_date\"] = pd.to_datetime(borough_data_test[\"created_date\"])\n",
    "    ax.plot(borough_data_test[\"created_date\"], borough_data_test[\"count\"], \"o\", color=colors[i], markersize=10, alpha=0.3, label=\"Observed\")\n",
    "\n",
    "    actual_series = borough_data_test.set_index('created_date')['count']\n",
    "    actual_aligned = actual_series.reindex(forecast.index, fill_value=0)\n",
    "\n",
    "    rmse = np.sqrt(np.mean((actual_aligned - forecast.values)**2))\n",
    "    rss = np.sqrt(np.sum((actual_aligned - forecast.values)**2))\n",
    "\n",
    "    ax.set_title(f\"{borough}\", fontsize=35)\n",
    "    ax.set_xlabel(\"Date\", fontsize=15)\n",
    "    ax.set_ylabel(\"Number of Rat Sightings\", fontsize=25)\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim(0,70)\n",
    "    ax.tick_params(axis='x', labelsize=24)\n",
    "    ax.tick_params(axis='y', labelsize=24)\n",
    "    text_box = Patch(facecolor='white', edgecolor='black', label=f'RMSE: {rmse}')\n",
    "    text_box2 = Patch(facecolor='white', edgecolor='black', label=f'RSS: {rss}')\n",
    "    ax.legend(handles=[ax.lines[0], text_box, text_box2], fontsize=22)\n",
    "    if borough == 'MANHATTAN':\n",
    "        RMSE.append(rmse)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "plt.suptitle(\"Daily Rat Sightings in NYC: Seasonal Average Forecast\", fontsize=36)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb4eb3",
   "metadata": {},
   "source": [
    "## SARIMA on MANHATTAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c779c",
   "metadata": {},
   "source": [
    "We try to model the number of daily rat sightings in Manhattan. We wish to beat the RMSE there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d628520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8267498",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = df[df['borough']=='MANHATTAN']\n",
    "\n",
    "rs['created_date'] = pd.to_datetime(rs['created_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2863c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(55,36))\n",
    "sm.graphics.tsa.plot_acf(rs['count'], lags = 365*2, ax=ax)\n",
    "plt.xlabel(\"Lag\",fontsize=24)\n",
    "plt.ylabel(\"Autocorrelation\",fontsize=30)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(55,36))\n",
    "sm.graphics.tsa.plot_pacf(rs['count'], lags = 365*2, ax=ax)\n",
    "plt.xlabel(\"Lag\",fontsize=24)\n",
    "plt.ylabel(\"Partial Autocorrelation\",fontsize=30)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d56a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as sm\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rs\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(y['created_date'], y['count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[y['created_date']< cut_off]\n",
    "y_test = y[y['created_date']>= cut_off]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d9443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A SARIMA model is not wise for seasonality of 1 year with daily data. Picking m = 7 is NOT appropriate here unless we \n",
    "# see seasonality with 7 day periods.\n",
    "# See https://alkaline-ml.com/pmdarima/2.0.1/tips_and_tricks.html?highlight=seasonal\n",
    "\n",
    "\n",
    "# Uncomment the line below to find AIC minimizing values to use for the ARIMA model. \n",
    "z = y_train['count'].to_numpy()\n",
    "#auto_arima(z, trace=True, error_action=\"ignore\", stepwise=True, seasonal=True, m = 3675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.ARIMA(z, order = (2, 1, 4), seasonal_order=(0,1,2,365)).fit()\n",
    "print(model.summary())\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(y_train['created_date'], y_train['count'], label=\"Training Data\")\n",
    "plt.plot(y_test['created_date'], y_test['count'], label=\"Test Data\")\n",
    "\n",
    "plt.plot(y_train['created_date'], model.fittedvalues, label=\"Fitted SARIMA Model\")\n",
    "plt.plot(y_test['created_date'], model.forecast(len(y_test['created_date'])), label=\"SARIMA Forecast\")\n",
    "\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_test['count'] - model.forecast(len(y_test['created_date'])))**2))\n",
    "\n",
    "RMSE.append(rmse)\n",
    "\n",
    "rss = np.sqrt(np.sum((y_test['count'] - model.forecast(len(y_test['created_date'])))**2))\n",
    "text_box = Patch(facecolor='white', edgecolor='black', label=f'RMSE: {rmse:.2f}')\n",
    "text_box2 = Patch(facecolor='white', edgecolor='black', label=f'RSS: {rss:.2f}')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "handles.extend([text_box, text_box2])\n",
    "labels.extend([f\"RMSE: {rmse:.6f}\", f\"RSS: {rss:.6f}\"])\n",
    "\n",
    "plt.legend(handles=handles, labels=labels, fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d86932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"For Manhattan and forecast from {cut_off} until {last_day}.\")\n",
    "print(f\"Improved from RMSE of {float(RMSE[0])} to {float(RMSE[1])}.\\n\")\n",
    "print(f\"This is a {round((1-(RMSE[1]/RMSE[0]))*100, 4)}% reduction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b98882",
   "metadata": {},
   "source": [
    "## SARIMA with Cross-Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "\n",
    "Xnew =  df.loc[df['borough'] == 'MANHATTAN'].set_index('created_date').sort_index()['count'].asfreq('D')\n",
    "Xnew = Xnew.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d97d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Initialize lists to store metrics for each split\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "mape_list = []\n",
    "# Parameters for rolling window\n",
    "window_size = 365  # Size of the initial training window\n",
    "test_size = 365    # Size of the test set for each rolling step\n",
    "X = Xnew  # Assuming this is the time series data\n",
    "X.fillna(0)\n",
    "# Loop through the data with a rolling window approach\n",
    "for start in range(0, len(X) - window_size - test_size + 1, 7):\n",
    "    # Define the training and test sets\n",
    "    train = X[start:start + window_size]\n",
    "    test = X[start + window_size:start + window_size + test_size]\n",
    "    # Fit the SARIMA model on the training data\n",
    "    model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(0, 1, 2, 7),\n",
    "                    enforce_stationarity=False, enforce_invertibility=False)\n",
    "\n",
    "    # it is unclear if these the best orders to use.\n",
    "\n",
    "\n",
    "    results = model.fit(disp=False, maxiter=50)\n",
    "    # Forecast on the test data\n",
    "    forecasts = results.predict(start=len(train), end=len(train) + len(test) - 1)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, forecasts)\n",
    "    mse = mean_squared_error(test, forecasts)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - forecasts) / test)) * 100\n",
    "    # Append metrics to their respective lists\n",
    "    mae_list.append(mae)\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    mape_list.append(mape)\n",
    "    # Print evaluation metrics for this split\n",
    "    print(f'Rolling Window {start + 1} - {start + window_size} | Test Period: {start + window_size + 1} - {start + window_size + test_size}')\n",
    "    print(f'MAE for this split: {mae}')\n",
    "    print(f'MSE for this split: {mse}')\n",
    "    print(f'RMSE for this split: {rmse}')\n",
    "    print(f'MAPE for this split: {mape:.2f}%\\n')\n",
    "# Calculate and print average values across all splits\n",
    "average_mae = np.mean(mae_list)\n",
    "average_mse = np.mean(mse_list)\n",
    "average_rmse = np.mean(rmse_list)\n",
    "average_mape = np.mean(mape_list)\n",
    "print(f'\\nAverage MAE: {average_mae}')\n",
    "print(f'Average MSE: {average_mse}')\n",
    "print(f'Average RMSE: {average_rmse}')\n",
    "print(f'Average MAPE: {average_mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa190f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6af8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ffb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
